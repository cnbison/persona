"""
OpenAIå®¢æˆ·ç«¯å°è£…
æä¾›ç»Ÿä¸€çš„GPT-4è°ƒç”¨æ¥å£ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶ã€æµå¼å“åº”ã€æˆæœ¬ç»Ÿè®¡
"""
import asyncio
import time
from typing import Optional, Dict, Any, AsyncIterator
from enum import Enum
from loguru import logger
import json

try:
    from openai import AsyncOpenAI, OpenAI
    from openai import Stream
    from openai.types import Completion
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    logger.warning("âš ï¸  OpenAIåŒ…æœªå®‰è£…ï¼Œå°†ä½¿ç”¨mockæ¨¡å¼")

from app.utils.config import settings


class ModelType(str, Enum):
    """æ”¯æŒçš„æ¨¡å‹ç±»å‹"""
    GPT4_TURBO = "gpt-4-turbo-preview"
    GPT4 = "gpt-4"
    GPT35_TURBO = "gpt-3.5-turbo"


class OpenAIClient:
    """
    OpenAIå®¢æˆ·ç«¯å°è£…ç±»

    åŠŸèƒ½ï¼š
    - ç»Ÿä¸€çš„è°ƒç”¨æ¥å£
    - è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
    - æµå¼å“åº”æ”¯æŒ
    - Tokenä½¿ç”¨ç»Ÿè®¡
    - æˆæœ¬è®¡ç®—
    """

    # æ¨¡å‹å®šä»·ï¼ˆç¾å…ƒ/1K tokensï¼‰- 2025å¹´ä»·æ ¼
    PRICING = {
        "gpt-4-turbo-preview": {"input": 0.01, "output": 0.03},
        "gpt-4": {"input": 0.03, "output": 0.06},
        "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015},
    }

    def __init__(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        if not OPENAI_AVAILABLE:
            logger.warning("âš ï¸  OpenAIæœªå®‰è£…ï¼Œä½¿ç”¨mockæ¨¡å¼")
            self.client = None
            self.async_client = None
            self.mock_mode = True
            return

        try:
            # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦é…ç½®
            if settings.openai_api_key == "sk-test-key":
                logger.warning("âš ï¸  ä½¿ç”¨æµ‹è¯•APIå¯†é’¥ï¼Œå®é™…è°ƒç”¨ä¼šå¤±è´¥")
                self.mock_mode = True
            else:
                self.mock_mode = False

            self.client = OpenAI(
                api_key=settings.openai_api_key,
                base_url=settings.openai_api_base
            )
            self.async_client = AsyncOpenAI(
                api_key=settings.openai_api_key,
                base_url=settings.openai_api_base
            )

            logger.info(f"âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {settings.openai_model})")

        except Exception as e:
            logger.error(f"âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.mock_mode = True
            self.client = None
            self.async_client = None

    async def chat_completion(
        self,
        messages: list,
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        stream: bool = False,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """
        èŠå¤©è¡¥å…¨APIï¼ˆå¼‚æ­¥ï¼‰

        å‚æ•°:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
                [{"role": "user", "content": "..."}, ...]
            model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®çš„æ¨¡å‹ï¼‰
            temperature: æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼‰
            max_tokens: æœ€å¤§tokenæ•°
            stream: æ˜¯å¦æµå¼è¿”å›
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        è¿”å›:
            {
                "content": "å“åº”å†…å®¹",
                "usage": {"prompt_tokens": 10, "completion_tokens": 20},
                "model": "gpt-4-turbo-preview",
                "cost": 0.0007
            }
        """
        if self.mock_mode:
            return self._mock_response(messages)

        model = model or settings.openai_model
        temperature = temperature or settings.openai_temperature

        for attempt in range(max_retries):
            try:
                logger.debug(f"ğŸ”„ è°ƒç”¨OpenAI API (å°è¯• {attempt + 1}/{max_retries})")

                response = await self.async_client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    stream=stream
                )

                # æå–å“åº”å†…å®¹
                if stream:
                    # æµå¼å“åº”éœ€è¦ç‰¹æ®Šå¤„ç†
                    content = ""
                    async for chunk in response:
                        if chunk.choices[0].delta.content:
                            content += chunk.choices[0].delta.content
                    completion_text = content
                    usage = None  # æµå¼å“åº”ä¸è¿”å›usage
                else:
                    completion_text = response.choices[0].message.content
                    usage = response.usage

                # è®¡ç®—æˆæœ¬
                cost = self._calculate_cost(model, usage) if usage else 0.0

                # è®°å½•ä½¿ç”¨æƒ…å†µ
                if usage:
                    logger.info(
                        f"âœ… OpenAIè°ƒç”¨æˆåŠŸ | "
                        f"è¾“å…¥: {usage.prompt_tokens} tokens | "
                        f"è¾“å‡º: {usage.completion_tokens} tokens | "
                        f"æˆæœ¬: ${cost:.4f}"
                    )

                return {
                    "content": completion_text,
                    "usage": {
                        "prompt_tokens": usage.prompt_tokens if usage else 0,
                        "completion_tokens": usage.completion_tokens if usage else 0,
                        "total_tokens": usage.total_tokens if usage else 0
                    } if usage else None,
                    "model": model,
                    "cost": cost
                }

            except Exception as e:
                logger.error(f"âŒ OpenAI APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")

                if attempt == max_retries - 1:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise

                # æŒ‡æ•°é€€é¿
                wait_time = 2 ** attempt
                logger.info(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                await asyncio.sleep(wait_time)

    def chat_completion_sync(
        self,
        messages: list,
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """
        èŠå¤©è¡¥å…¨APIï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

        å‚æ•°å’Œè¿”å›å€¼ä¸å¼‚æ­¥ç‰ˆæœ¬ç›¸åŒ
        """
        if self.mock_mode:
            return self._mock_response(messages)

        model = model or settings.openai_model
        temperature = temperature or settings.openai_temperature

        for attempt in range(max_retries):
            try:
                logger.debug(f"ğŸ”„ è°ƒç”¨OpenAI API (å°è¯• {attempt + 1}/{max_retries})")

                response = self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )

                completion_text = response.choices[0].message.content
                usage = response.usage
                cost = self._calculate_cost(model, usage)

                logger.info(
                    f"âœ… OpenAIè°ƒç”¨æˆåŠŸ | "
                    f"è¾“å…¥: {usage.prompt_tokens} tokens | "
                    f"è¾“å‡º: {usage.completion_tokens} tokens | "
                    f"æˆæœ¬: ${cost:.4f}"
                )

                return {
                    "content": completion_text,
                    "usage": {
                        "prompt_tokens": usage.prompt_tokens,
                        "completion_tokens": usage.completion_tokens,
                        "total_tokens": usage.total_tokens
                    },
                    "model": model,
                    "cost": cost
                }

            except Exception as e:
                logger.error(f"âŒ OpenAI APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")

                if attempt == max_retries - 1:
                    raise

                wait_time = 2 ** attempt
                logger.info(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)

    def _calculate_cost(self, model: str, usage) -> float:
        """è®¡ç®—APIè°ƒç”¨æˆæœ¬"""
        if not usage:
            return 0.0

        pricing = self.PRICING.get(model, {"input": 0.01, "output": 0.03})
        input_cost = (usage.prompt_tokens / 1000) * pricing["input"]
        output_cost = (usage.completion_tokens / 1000) * pricing["output"]

        return input_cost + output_cost

    def _mock_response(self, messages: list) -> Dict[str, Any]:
        """
        Mockå“åº”ï¼ˆç”¨äºå¼€å‘æµ‹è¯•ï¼‰
        """
        last_message = messages[-1]["content"] if messages else ""

        mock_content = f"[Mockå“åº”] è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„OpenAIå“åº”ã€‚\n\nä½ çš„è¾“å…¥æ˜¯ï¼š{last_message[:100]}...\n\né…ç½®çœŸå®APIå¯†é’¥åå³å¯è°ƒç”¨å®é™…APIã€‚"

        return {
            "content": mock_content,
            "usage": {
                "prompt_tokens": 10,
                "completion_tokens": 20,
                "total_tokens": 30
            },
            "model": settings.openai_model,
            "cost": 0.0
        }


# å…¨å±€å•ä¾‹
_openai_client: Optional[OpenAIClient] = None


def get_openai_client() -> OpenAIClient:
    """
    è·å–OpenAIå®¢æˆ·ç«¯å•ä¾‹

    ä½¿ç”¨æ–¹å¼:
        client = get_openai_client()
        response = await client.chat_completion(messages)
    """
    global _openai_client
    if _openai_client is None:
        _openai_client = OpenAIClient()
    return _openai_client


# ä¾¿æ·å‡½æ•°
async def call_openai(
    messages: list,
    model: Optional[str] = None,
    temperature: Optional[float] = None
) -> str:
    """
    ä¾¿æ·çš„OpenAIè°ƒç”¨å‡½æ•°ï¼ˆåªè¿”å›å†…å®¹ï¼‰

    ä½¿ç”¨æ–¹å¼:
        response = await call_openai([{"role": "user", "content": "ä½ å¥½"}])
    """
    client = get_openai_client()
    result = await client.chat_completion(
        messages=messages,
        model=model,
        temperature=temperature
    )
    return result["content"]


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import asyncio

    async def test():
        """æµ‹è¯•OpenAIå®¢æˆ·ç«¯"""
        client = get_openai_client()

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹Pythonç¼–ç¨‹è¯­è¨€ã€‚"}
        ]

        try:
            response = await client.chat_completion(messages)
            print("å“åº”å†…å®¹:")
            print(response["content"])
            print(f"\nä½¿ç”¨æƒ…å†µ: {response['usage']}")
            print(f"æˆæœ¬: ${response['cost']:.4f}")
        except Exception as e:
            print(f"é”™è¯¯: {e}")

    # è¿è¡Œæµ‹è¯•
    asyncio.run(test())
