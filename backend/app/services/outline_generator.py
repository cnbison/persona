"""
æçº²ç”ŸæˆæœåŠ¡
åŸºäºè‘—ä½œå’ŒPersonaç”Ÿæˆ10é›†èŠ‚ç›®æçº²
"""
import json
from typing import List, Dict, Any, Optional
from loguru import logger
import uuid

from app.models.persona import AuthorPersona
from app.models.book import Book
from app.models.dialogue import EpisodeOutline, HotTopicMatch, BookSeries
from app.utils.openai_client import get_openai_client


class OutlineGenerator:
    """
    æçº²ç”ŸæˆæœåŠ¡

    åŠŸèƒ½ï¼š
    - åˆ†æè‘—ä½œç»“æ„
    - ç”Ÿæˆ10é›†æçº²
    - æ¯é›†åˆ†é…ç« èŠ‚
    - åŒ¹é…çƒ­ç‚¹è¯é¢˜
    - å®šä¹‰è®¨è®ºé‡ç‚¹
    """

    # æçº²ç”ŸæˆPromptæ¨¡æ¿
    OUTLINE_GENERATION_PROMPT = """
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ’­å®¢åˆ¶ä½œäººã€‚è¯·åŸºäºä»¥ä¸‹è‘—ä½œä¿¡æ¯ï¼Œè®¾è®¡ä¸€ä¸ª10é›†çš„æ·±åº¦å¯¹è¯èŠ‚ç›®æçº²ã€‚

ã€è‘—ä½œä¿¡æ¯ã€‘
æ ‡é¢˜ï¼š{title}
ä½œè€…ï¼š{author}
æ€»ç« èŠ‚æ•°ï¼š{total_chapters}
æ ¸å¿ƒä¸»é¢˜ï¼š{main_themes}

ã€ç« èŠ‚æ¦‚è§ˆã€‘
{chapters_overview}

ã€æ ¸å¿ƒè§‚ç‚¹ç¤ºä¾‹ã€‘
{viewpoints_sample}

è¯·è®¾è®¡10é›†èŠ‚ç›®ï¼Œè¦æ±‚ï¼š
1. æ¯é›†èšç„¦ç‰¹å®šä¸»é¢˜/ç« èŠ‚ï¼Œä¸»é¢˜æ˜ç¡®ä¸”æœ‰å¸å¼•åŠ›
2. 10é›†å†…å®¹è¦†ç›–è‘—ä½œæ ¸å¿ƒå†…å®¹90%ä»¥ä¸Šï¼Œé¿å…é—æ¼é‡è¦ç« èŠ‚
3. é€»è¾‘é€’è¿›ï¼Œç”±æµ…å…¥æ·±ï¼šä»èƒŒæ™¯ä»‹ç» â†’ æ ¸å¿ƒæ¦‚å¿µ â†’ æ·±åº¦æ¢è®¨ â†’ ç°ä»£æ„ä¹‰
4. æ¯é›†åŒ…å«æ˜ç¡®çš„è®¨è®ºé‡ç‚¹ï¼Œè‡³å°‘5ä¸ª
5. æ¯é›†ä¸»é¢˜è¦èƒ½è®©å¬ä¼—äº§ç”Ÿå…±é¸£å’Œå¥½å¥‡

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š

{{
  "episodes": [
    {{
      "episode_number": 1,
      "theme": "æœ¬é›†ä¸»é¢˜ï¼ˆ20å­—ä»¥å†…ï¼Œå¸å¼•äººï¼‰",
      "target_chapters": ["ç« èŠ‚1", "ç« èŠ‚2"],
      "discussion_points": [
        "å…·ä½“è®¨è®ºç‚¹1ï¼ˆæ˜ç¡®è¦æ¢è®¨çš„é—®é¢˜ï¼‰",
        "å…·ä½“è®¨è®ºç‚¹2",
        "å…·ä½“è®¨è®ºç‚¹3",
        "å…·ä½“è®¨è®ºç‚¹4",
        "å…·ä½“è®¨è®ºç‚¹5"
      ]
    }}
  ]
}}

è¦æ±‚ï¼š
- target_chapterså¿…é¡»åŸºäºå®é™…ç« èŠ‚æ ‡é¢˜
- discussion_pointsè‡³å°‘5ä¸ªï¼Œè¦å…·ä½“ã€æ·±å…¥ã€å¯è®¨è®º
- ä¸»é¢˜è¦é€šä¿—æ˜“æ‡‚ï¼Œé€‚åˆå¤§ä¼—å¬ä¼—
- 10é›†ä¹‹é—´è¦æœ‰é€»è¾‘é€’è¿›å…³ç³»

è¯·åªè¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚
"""

    def __init__(self):
        """åˆå§‹åŒ–æçº²ç”Ÿæˆå™¨"""
        self.openai_client = get_openai_client()
        logger.info("âœ… æçº²ç”ŸæˆæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")

    async def generate_outline(
        self,
        book: Book,
        persona: AuthorPersona,
        episodes_count: int = 10
    ) -> BookSeries:
        """
        ç”Ÿæˆ10é›†æçº²

        å‚æ•°:
            book: è‘—ä½œå¯¹è±¡
            persona: ä½œè€…Persona
            episodes_count: é›†æ•°ï¼ˆé»˜è®¤10ï¼‰

        è¿”å›:
            BookSerieså¯¹è±¡ï¼ˆåŒ…å«10é›†EpisodeOutlineï¼‰
        """
        logger.info(f"ğŸ“ å¼€å§‹ç”Ÿæˆæçº²: {book.title} ({episodes_count}é›†)")

        # å‡†å¤‡è¾“å…¥æ•°æ®
        chapters_overview = self._prepare_chapters_overview(book)
        viewpoints_sample = self._prepare_viewpoints_sample(book)
        main_themes = self._extract_main_themes(book)

        # è°ƒç”¨GPT-4ç”Ÿæˆæçº²
        logger.info("ğŸ¤– æ­£åœ¨è°ƒç”¨GPT-4ç”Ÿæˆæçº²...")
        episodes_data = await self._generate_episodes_with_gpt(
            book=book,
            chapters_overview=chapters_overview,
            viewpoints_sample=viewpoints_sample,
            main_themes=main_themes
        )

        # åˆ›å»ºBookSerieså¯¹è±¡
        series = BookSeries(
            series_id=str(uuid.uuid4()),
            book_id=book.book_id,
            book_title=book.title,
            author_name=book.author,
            total_episodes=episodes_count
        )

        # ä¸ºæ¯é›†åˆ›å»ºEpisodeOutline
        for episode_data in episodes_data['episodes']:
            # æŸ¥æ‰¾å¯¹åº”çš„ç« èŠ‚ID
            target_chapter_ids = self._match_chapters_by_title(
                book,
                episode_data['target_chapters']
            )

            # åŒ¹é…çƒ­ç‚¹è¯é¢˜
            hot_topics = await self._match_hot_topics(
                episode_data['theme'],
                episode_data['discussion_points']
            )

            # åˆ›å»ºEpisodeOutline
            # ç”ŸæˆåŸºæœ¬æµç¨‹è®¾è®¡
            flow_design = {
                "opening": f"ä¸»æŒäººå¼€åœºï¼Œå¼•å…¥æœ¬é›†ä¸»é¢˜ï¼š{episode_data['theme']}",
                "book_exploration": f"ä½œè€…ä¸»è®²ï¼Œæ¢è®¨{episode_data['target_chapters'][0] if episode_data['target_chapters'] else 'ç›¸å…³ç« èŠ‚'}çš„æ ¸å¿ƒè§‚ç‚¹",
                "hot_topic_connection": f"ç»“åˆç°ä»£çƒ­ç‚¹è¯é¢˜ï¼Œæ¢è®¨{episode_data['theme']}çš„ç°å®æ„ä¹‰",
                "deep_discussion": "ä¸»æŒäººä¸ä½œè€…æ·±åº¦æ€è¾¨ï¼Œå±•å¼€å¤šå±‚æ¬¡è®¨è®º",
                "conclusion": "æ€»ç»“å‡åï¼Œæå‡ºå¯å‘æ€§æ€è€ƒ"
            }

            episode_outline = EpisodeOutline(
                outline_id=str(uuid.uuid4()),
                book_id=book.book_id,
                episode_number=episode_data['episode_number'],
                theme=episode_data['theme'],
                target_chapters=episode_data['target_chapters'],
                discussion_points=episode_data['discussion_points'],
                hot_topics=hot_topics,
                flow_design=flow_design,
                estimated_duration=30
            )

            series.outlines.append(episode_outline)

        logger.info(f"âœ… æçº²ç”Ÿæˆå®Œæˆ: {len(series.outlines)}é›†")
        return series

    async def update_episode(
        self,
        outline_id: str,
        episode_number: int,
        updates: Dict[str, Any]
    ) -> bool:
        """
        æ›´æ–°å•é›†æçº²

        å‚æ•°:
            outline_id: æçº²ID
            episode_number: é›†æ•°
            updates: æ›´æ–°å†…å®¹

        è¿”å›:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        # TODO: å®ç°æ›´æ–°é€»è¾‘
        # 1. ä»æ•°æ®åº“åŠ è½½outline
        # 2. æ‰¾åˆ°å¯¹åº”episode
        # 3. åº”ç”¨æ›´æ–°
        # 4. ä¿å­˜åˆ°æ•°æ®åº“

        logger.info(f"âœï¸  æ›´æ–°ç¬¬{episode_number}é›†æçº²")
        return True

    def _prepare_chapters_overview(self, book: Book) -> str:
        """å‡†å¤‡ç« èŠ‚æ¦‚è§ˆ"""
        overview_parts = []

        for chapter in book.chapters:
            # å–å‰200å­—ä½œä¸ºæ¦‚è§ˆ
            preview = chapter.content[:200] + "..." if len(chapter.content) > 200 else chapter.content
            overview_parts.append(f"- {chapter.title}: {preview}")

        return "\n".join(overview_parts[:10])  # æœ€å¤š10ç« 

    def _prepare_viewpoints_sample(self, book: Book) -> str:
        """å‡†å¤‡æ ¸å¿ƒè§‚ç‚¹æ ·æœ¬"""
        sample_parts = []

        for vp in book.core_viewpoints[:10]:  # å–å‰10ä¸ª
            sample_parts.append(f"- {vp.content}")

        return "\n".join(sample_parts)

    def _extract_main_themes(self, book: Book) -> List[str]:
        """æå–ä¸»è¦ä¸»é¢˜"""
        # åŸºäºå…³é”®è¯æå–ä¸»é¢˜
        all_keywords = []
        for vp in book.core_viewpoints:
            all_keywords.extend(vp.keywords)

        # ç»Ÿè®¡é«˜é¢‘è¯
        from collections import Counter
        keyword_freq = Counter(all_keywords)

        # å–å‰5ä¸ªä½œä¸ºä¸»è¦ä¸»é¢˜
        main_themes = [kw for kw, _ in keyword_freq.most_common(5)]
        return main_themes

    async def _generate_episodes_with_gpt(
        self,
        book: Book,
        chapters_overview: str,
        viewpoints_sample: str,
        main_themes: List[str]
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨GPT-4ç”Ÿæˆé›†æ•°è§„åˆ’

        è¿”å›: è§£æåçš„JSONå­—å…¸
        """
        # æ„å»ºPrompt
        prompt = self.OUTLINE_GENERATION_PROMPT.format(
            title=book.title,
            author=book.author,
            total_chapters=len(book.chapters),
            main_themes="ã€".join(main_themes),
            chapters_overview=chapters_overview[:3000],  # é™åˆ¶é•¿åº¦
            viewpoints_sample=viewpoints_sample
        )

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ’­å®¢åˆ¶ä½œäººã€‚"},
            {"role": "user", "content": prompt}
        ]

        try:
            # è°ƒç”¨OpenAI
            response = await self.openai_client.chat_completion(
                messages=messages,
                temperature=0.5
            )

            # è§£æJSON
            content = response['content']
            if '```json' in content:
                content = content.split('```json')[1].split('```')[0]
            elif '```' in content:
                content = content.split('```')[1].split('```')[0]

            episodes_data = json.loads(content.strip())
            return episodes_data

        except Exception as e:
            logger.error(f"âŒ æçº²ç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›Mockæ•°æ®
            return self._get_mock_episodes(book)

    async def _match_hot_topics(
        self,
        theme: str,
        discussion_points: List[str]
    ) -> List[HotTopicMatch]:
        """
        åŒ¹é…çƒ­ç‚¹è¯é¢˜

        å‚æ•°:
            theme: é›†æ•°ä¸»é¢˜
            discussion_points: è®¨è®ºé‡ç‚¹

        è¿”å›:
            åŒ¹é…çš„çƒ­ç‚¹è¯é¢˜åˆ—è¡¨
        """
        # TODO: å®ç°çƒ­ç‚¹åŒ¹é…é€»è¾‘
        # 1. è°ƒç”¨çƒ­ç‚¹APIæˆ–æŸ¥è¯¢çƒ­ç‚¹æ•°æ®åº“
        # 2. è®¡ç®—ç›¸å…³æ€§è¯„åˆ†
        # 3. ç­›é€‰é«˜ç›¸å…³æ€§è¯é¢˜

        # åŸºäºä¸»é¢˜å…³é”®è¯ç”Ÿæˆä¸åŒçš„çƒ­ç‚¹è¯é¢˜
        hot_topic_map = {
            "å­¦ä¹ ": "ç°ä»£æ•™è‚²ä½“ç³»ä¸ç»ˆèº«å­¦ä¹ ",
            "å®è·µ": "ç†è®ºä¸å®è·µçš„ç»“åˆ",
            "æ²»å›½": "ç°ä»£æ²»ç†ä¸ç¤¾ä¼šè´£ä»»",
            "å¾·æ”¿": "é“å¾·é¢†å¯¼åŠ›ä¸ä¼ä¸šç®¡ç†",
            "ç¤¼ä¹": "æ–‡åŒ–ä¼ æ‰¿ä¸ç°ä»£ç¤¼ä»ª",
            "ä»çˆ±": "äººé™…å…³ç³»ä¸å¿ƒç†å¥åº·",
            "é“å¾·": "èŒä¸šæ“å®ˆä¸ç¤¾ä¼šé“å¾·",
            "å›å­": "äººæ ¼å¡‘é€ ä¸è‡ªæˆ‘æå‡",
            "æ™ºæ…§": "æ‰¹åˆ¤æ€§æ€ç»´ä¸å†³ç­–",
            "è¨€è¾": "æ²Ÿé€šæŠ€å·§ä¸è¡¨è¾¾",
            "è¡Œä¸º": "è¡Œä¸ºè§„èŒƒä¸èŒåœºç¤¼ä»ª",
            "ç¤¾ä¼š": "å…¬æ°‘å‚ä¸å’Œç¤¾ä¼šè´£ä»»"
        }

        # æ‰¾åˆ°åŒ¹é…çš„çƒ­ç‚¹è¯é¢˜
        matched_topic = "å½“ä»£ç¤¾ä¼šçƒ­ç‚¹è¯é¢˜"
        for keyword, topic in hot_topic_map.items():
            if keyword in theme or keyword in str(discussion_points):
                matched_topic = topic
                break

        mock_topics = [
            HotTopicMatch(
                topic_title=matched_topic,
                topic_description=f"ä¸ã€Š{theme}ã€‹ä¸»é¢˜ç›¸å…³çš„ç°ä»£ç¤¾ä¼šè®¨è®º",
                relevance_score=0.85,
                connection_point=f"ä»{theme}çš„è§’åº¦æ€è€ƒç°ä»£{matched_topic.split('ä¸')[-1] if 'ä¸' in matched_topic else matched_topic}"
            )
        ]

        return mock_topics

    def _match_chapters_by_title(
        self,
        book: Book,
        chapter_titles: List[str]
    ) -> List[str]:
        """æ ¹æ®ç« èŠ‚æ ‡é¢˜åŒ¹é…ç« èŠ‚ID"""
        matched_ids = []

        for title in chapter_titles:
            # æ¨¡ç³ŠåŒ¹é…
            for chapter in book.chapters:
                if title in chapter.title or chapter.title in title:
                    matched_ids.append(chapter.chapter_id)
                    break

        return matched_ids

    def _get_mock_episodes(self, book: Book) -> Dict[str, Any]:
        """è·å–Mockæçº²æ•°æ®ï¼ˆç”¨äºå¼€å‘æµ‹è¯•ï¼‰"""
        return {
            "episodes": [
                {
                    "episode_number": 1,
                    "theme": f"ã€Š{book.title}ã€‹çš„å†™ä½œèƒŒæ™¯",
                    "target_chapters": ["åºè¨€", "ç¬¬ä¸€ç« "],
                    "discussion_points": [
                        "ä½œè€…å†™ä½œçš„å†å²èƒŒæ™¯",
                        "è‘—ä½œçš„æ ¸å¿ƒé—®é¢˜æ„è¯†",
                        "åœ¨å½“ä»£çš„ç°å®æ„ä¹‰"
                    ]
                },
                {
                    "episode_number": 2,
                    "theme": "æ ¸å¿ƒæ¦‚å¿µè§£æ",
                    "target_chapters": ["ç¬¬äºŒç« ", "ç¬¬ä¸‰ç« "],
                    "discussion_points": [
                        "å…³é”®æœ¯è¯­çš„å®šä¹‰",
                        "æ¦‚å¿µä¹‹é—´çš„é€»è¾‘å…³ç³»",
                        "å¸¸è§è¯¯è§£è¾¨æ"
                    ]
                }
            ]
        }


# å…¨å±€å•ä¾‹
_outline_generator: Optional[OutlineGenerator] = None


def get_outline_generator() -> OutlineGenerator:
    """è·å–æçº²ç”Ÿæˆå™¨å•ä¾‹"""
    global _outline_generator
    if _outline_generator is None:
        _outline_generator = OutlineGenerator()
    return _outline_generator


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import asyncio

    async def test():
        """æµ‹è¯•æçº²ç”Ÿæˆ"""
        generator = get_outline_generator()

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        from app.models.book import Book, Chapter, CoreViewpoint
        from app.models.persona import AuthorPersona, ThinkingStyle

        test_book = Book(
            book_id="test-001",
            title="ç†æƒ³å›½",
            author="æŸæ‹‰å›¾",
            language="zh",
            file_path="/fake/path.pdf",
            file_type="pdf",
            chapters=[
                Chapter(
                    chapter_id="ch-001",
                    chapter_number=1,
                    title="ç¬¬ä¸€å·",
                    content="æ­£ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿè¿™æ˜¯æœ¬å·çš„æ ¸å¿ƒé—®é¢˜..."
                ),
                Chapter(
                    chapter_id="ch-002",
                    chapter_number=2,
                    title="ç¬¬äºŒå·",
                    content="å…³äºç†æƒ³å›½å®¶çš„æ„æƒ³..."
                )
            ],
            core_viewpoints=[
                CoreViewpoint(
                    viewpoint_id="vp-001",
                    content="æ­£ä¹‰æ˜¯æœ€é«˜çš„ç¾å¾·",
                    original_text="æ­£ä¹‰æ˜¯æœ€é«˜çš„ç¾å¾·",
                    chapter_id="ch-001",
                    context="..."
                )
            ]
        )

        test_persona = AuthorPersona(
            persona_id="persona-001",
            author_name="æŸæ‹‰å›¾",
            book_id="test-001",
            thinking_style=ThinkingStyle.DIALECTICAL,
            logic_pattern="è¾©è¯æ³•",
            reasoning_framework="è‹æ ¼æ‹‰åº•é—®ç­”æ³•",
            core_philosophy="è¿½æ±‚çœŸç†å’Œæ­£ä¹‰",
            theoretical_framework="ç†å¿µè®º",
            key_concepts={"ç†å¿µ": "æ°¸æ’çœŸå®"},
            narrative_style="ä¸¥è‚ƒ",
            language_rhythm="æ²‰ç¨³",
            sentence_structure="å¤æ‚",
            rhetorical_devices=["æ¯”å–»"],
            value_orientation="ç†æƒ³ä¸»ä¹‰",
            value_judgment_framework="ä»¥çœŸç†ä¸ºæ ‡å‡†",
            core_positions=["æ­£ä¹‰è‡³ä¸Š"],
            opposed_positions=[" relativism"],
            tone="æ¸©å’Œ",
            emotion_tendency="ç†æ€§",
            expressiveness="å§”å©‰",
            personality_traits=["æ™ºæ…§"],
            communication_style="å¯¹è¯",
            attitude_toward_audience="å°Šé‡"
        )

        try:
            # ç”Ÿæˆæçº²
            outline = await generator.generate_outline(test_book, test_persona)

            print(f"âœ… æçº²ç”ŸæˆæˆåŠŸ!")
            print(f"æçº²ID: {outline.outline_id}")
            print(f"æ€»é›†æ•°: {outline.total_episodes}")

            print("\né›†æ•°åˆ—è¡¨:")
            for episode in outline.episodes:
                print(f"  ç¬¬{episode['episode_number']}é›†: {episode['theme']}")
                print(f"    è®¨è®º: {', '.join(episode['discussion_points'][:2])}")

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # è¿è¡Œæµ‹è¯•
    asyncio.run(test())
